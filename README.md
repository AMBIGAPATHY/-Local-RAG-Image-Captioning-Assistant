# ğŸ“˜ Local RAG + Image Captioning Assistant  
### *A Hybrid Retrieval-Augmented Generation + Vision AI System*  
### **Created & Built by _AMBIGAPATHY. S_ â€” AI & ML Engineer | Data Scientist**

---

## ğŸ¥ Demo Video  
ğŸ‘‰ **Watch the full project demo:**  
https://drive.google.com/file/d/1PjkU1pYwZsILEGmUO28R4XK6GmaT1j2U/view?usp=sharing 


---

# ğŸ“Œ 1. Project Overview

This project is a **hybrid AI assistant** that integrates:

### âœ… Retrieval-Augmented Generation (Mini-RAG)  
- Uses **3 PDFs** (AI, ML, and Statistics)  
- Splits them into **700-character chunks** with **150-character overlap**  
- Generates local embeddings using **all-MiniLM-L6-v2**  
- Stores everything in **SQLite vector DB (rag.db)**  
- Performs **semantic search (cosine similarity)**  
- Sends top_k chunks to **Gemini 2.5 Flash** for grounded answers  

### âœ… Image Captioning (Vision Model)  
- Users can upload images  
- Gemini 2.5 Vision generates:  
  - A **short caption**  
  - **3 keyword tags**  
  - In **strict JSON format**  
- Image preview shown inside chat  
- Metadata stored in DB  

### â­ Bonus Features  
- Multi-chat support  
- Auto chat naming  
- Dark-themed UI (Dash + Bootstrap)  
- Persistent chat history  
- Efficient backend caching  
- Local model storage (MiniLM)

---

# ğŸ§± 2. System Architecture

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚             Dash UI            â”‚
                 â”‚  (Chat, Image Upload, History) â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                              Callbacks
                                   â”‚
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚      RAG Backend       â”‚
                     â”‚   (rag_backend.py)     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚  SentenceTransformer: MiniLM-L6-v2    â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚       SQLite Vector Databases        â”‚
               â”‚   rag.db + chat_history.db           â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚             Gemini API               â”‚
               â”‚       2.5 Flash (text + vision)      â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“ 3. Folder Structure

```
project/
â”‚
â”œâ”€â”€ app_dash.py
â”œâ”€â”€ rag_backend.py
â”œâ”€â”€ chat_db.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”‚
â”œâ”€â”€ assets/
â”‚   â”œâ”€â”€ data/pdfs/
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â”œâ”€â”€ rag.db
â”‚   â”‚   â””â”€â”€ chat_history.db
â”‚   â””â”€â”€ models/all-MiniLM-L6-v2/
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ build_index.py
â”‚
â””â”€â”€ callbacks/
    â””â”€â”€ chat_callbacks.py
```

---

# âš™ï¸ 4. Installation & Setup

### **Step 1: Clone Repo**
```bash
git clone https://github.com/your-repo/project.git
cd project
```

### **Step 2: Create Virtual Environment**
```bash
python -m venv vvenv            # USE: Python 3.10.+ and I was using 3.10.9 for this
source venv/bin/activate        # Windows: venv\Scripts\activate
```

### **Step 3: Install Requirements**
```bash
pip install -r requirements.txt
```

### **Step 4: Add Gemini API Key**
Create a `.env` file:

```
GEMINI_API_KEY=your-api-key-here
```

---

# ğŸ”¨ 5. Build the Vector Database (RAG Index)

Run:

```bash
python scripts/build_index.py
```

This script will:

- Load the PDFs  
- Split into chunks  
- Embed using MiniLM-L6-v2  
- Store text + embeddings inside **rag.db**

---

# ğŸ—ƒï¸ 6. chat_db.py â€” Automatic Database Handling

âœ” `chat_db.py` is executed automatically when the app starts  
âœ” It checks if `chat_history.db` already exists  
âœ” **If DB exists â†’ do nothing**  
âœ” **If not â†’ create required tables**

You **never need to manually run** this file.

---

# â–¶ï¸ 7. Run the Application

```bash
python app_dash.py
```

Open in browser:  
ğŸ‘‰ http://127.0.0.1:8050/

---

# ğŸ” 8. How the RAG Pipeline Works

### **1. PDFs â†’ Chunks (700 chars)**  
Chunks overlap by **150 chars** to avoid sentence breaks.

### **2. Chunk â†’ Embedding**  
Using `all-MiniLM-L6-v2`.

### **3. Store in SQLite Vector DB**  
Each row = chunk_text + embedding + metadata.

### **4. User Query â†’ Embedding**

### **5. Cosine Similarity Search**  
Retrieve `top_k` most relevant chunks.

### **6. LLM Answer**  
Send:
- System prompt  
- Query  
- Retrieved chunks  

to **Gemini 2.5 Flash**.

### **7. Display Answer in Chat**

---

# ğŸ–¼ï¸ 9. Image Captioning Flow

1. User uploads an image  
2. Converted from base64 â†’ PIL Image  
3. Sent to Gemini 2.5 Vision  
4. Returns **strict JSON**:

```json
{
  "caption": "A laptop on a wooden desk with coffee.",
  "tags": ["laptop", "workspace", "coffee"]
}
```

5. Image & tags saved in chat history  

---

# ğŸ’¬ 10. Chat History Features

- Multi-chat system  
- Rename chats  
- Delete chats  
- Auto-title based on first message  
- Image preview in chat history  
- Fully persistent using SQLite  

---

# ğŸ§ª 11. Assignment Requirement Mapping

| Requirement | Status |
|------------|--------|
| RAG over 3 PDFs | âœ” Done |
| 700-char chunks + overlap | âœ” Implemented |
| Local embeddings | âœ” MiniLM-L6-v2 |
| SQLite vector DB | âœ” rag.db |
| Image captioning (JSON) | âœ” Done |
| History awareness | âœ” Implemented |
| Efficient cosine similarity | âœ” Yes |
| Chat system | âœ” Advanced |
| Automatic DB handling | âœ” chat_db.py |
| UI | âœ” Beautiful Dash Interface |

---

# ğŸ“œ 12. Future Enhancements

- Telegram / Discord bot interface  
- Source highlighting in responses  
- FAISS or sqlite-vec ANN search  
- Cloud deployment  

---

# ğŸ 13. Conclusion

This project showcases a **fully functional AI assistant** combining:

- Local vector search  
- RAG over PDFs  
- Vision captioning  
- Persistent chat system  
- Gemini-powered LLM responses  
- Clean, dark-themed UI  

It fully satisfies the **Data Science Assignment** requirements and includes advanced features beyond the expected scope.

---

# âœ¨ Author

**Created & Built by  
_â¡ï¸ AMBIGAPATHY. S_  
AI & ML Engineer | Data Scientist**

---

# ğŸ“¬ Contact
ğŸ‘‰   https://www.linkedin.com/in/ambigapathy-s  
For improvements, suggestions, or collaborations â€” feel free to reach out!
